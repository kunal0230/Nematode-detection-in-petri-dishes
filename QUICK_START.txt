╔══════════════════════════════════════════════════════════════════════════════╗
║                                                                              ║
║          WORM DETECTION ML PIPELINE - QUICK START GUIDE               ║
║                                                                              ║
╚══════════════════════════════════════════════════════════════════════════════╝

WHAT YOU RECEIVED
═══════════════════════════════════════════════════════════════════════════════

✓ worm_annotation_tool.html      → Interactive labeling tool
✓ data_augmentation.py            → Data augmentation pipeline  
✓ ml_model_training.py            → ML model & training code
✓ complete_workflow.py            → End-to-end example
✓ README.md                       → Full documentation


GETTING STARTED (5 STEPS)
═══════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────────┐
│ STEP 1: ANNOTATE YOUR IMAGES (Manual Labeling)                             │
└─────────────────────────────────────────────────────────────────────────────┘

1. Open worm_annotation_tool.html in your web browser
   
2. Click "Load Image" and select a petri dish image

3. Select "Bounding Box" tool

4. Click and drag to draw boxes around each worm

5. Click "Export YOLO Format" to save annotations

6. Repeat for at least 5-10 images

- Organize your files:
   raw_data/
   ├── images/
   │   ├── dish_001.jpg
   │   └── dish_002.jpg
   └── labels/
       ├── dish_001.txt
       └── dish_002.txt


┌─────────────────────────────────────────────────────────────────────────────┐
│ STEP 2: GENERATE AUGMENTED DATA (Expand Your Dataset)                      │
└─────────────────────────────────────────────────────────────────────────────┘

Run this Python code:

```python
from data_augmentation import WormDataAugmentor

augmentor = WormDataAugmentor(output_dir='augmented_worm_data')

# Process each image
augmentor.generate_augmentations(
    image_path='raw_data/images/dish_001.jpg',
    label_path='raw_data/labels/dish_001.txt',
    num_augmentations=20,
    format='yolo'
)
```

Result: 5 images -> 100+ training samples!


┌─────────────────────────────────────────────────────────────────────────────┐
│ STEP 3: INSTALL PYTORCH (One-time Setup)                                   │
└─────────────────────────────────────────────────────────────────────────────┘

For GPU (CUDA):
  pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

For CPU only:
  pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

Test installation:
  python -c "import torch; print(torch.__version__)"


┌─────────────────────────────────────────────────────────────────────────────┐
│ STEP 4: TRAIN YOUR MODEL                                                   │
└─────────────────────────────────────────────────────────────────────────────┘

Option A: Use the complete workflow script
  python complete_workflow.py

Option B: Custom training code
```python
from ml_model_training import WormDetectionTrainer, WormDetectionDataset
from torch.utils.data import DataLoader, random_split

# Create dataset
dataset = WormDetectionDataset(
    image_dir='augmented_worm_data/images',
    label_dir='augmented_worm_data/labels'
)

# Split train/val
train_dataset, val_dataset = random_split(dataset, [int(0.8*len(dataset)), 
                                                     int(0.2*len(dataset))])

# Create loaders
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, 
                          collate_fn=lambda x: tuple(zip(*x)))
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,
                        collate_fn=lambda x: tuple(zip(*x)))

# Train
trainer = WormDetectionTrainer(model_type='fasterrcnn', num_classes=2)
history = trainer.train(train_loader, val_loader, num_epochs=50, lr=0.001)
```

- Training time: 2-3 hours (GPU) or 8-12 hours (CPU)


┌─────────────────────────────────────────────────────────────────────────────┐
│ STEP 5: DETECT WORMS IN NEW IMAGES                                         │
└─────────────────────────────────────────────────────────────────────────────┘

```python
# Load trained model
trainer.load_model('best_worm_detector.pth')

# Predict
predictions = trainer.predict('new_dish.jpg', confidence_threshold=0.5)

print(f"Found {len(predictions['boxes'])} worms!")

# Visualize
trainer.visualize_predictions('new_dish.jpg', save_path='result.png')
```


TIPS FOR SUCCESS
═══════════════════════════════════════════════════════════════════════════════

✓ START SMALL: 5-10 well-annotated images is enough!

✓ QUALITY > QUANTITY: Accurate labels matter more than many images

✓ USE AUGMENTATION: 20x augmentation can turn 10 images into 200 samples

✓ TIGHT BOXES: Draw bounding boxes close to the worm boundaries

✓ INCLUDE ALL WORMS: Even partially visible worms should be labeled

✓ BE CONSISTENT: Label similar objects the same way every time

✓ CHECK AUGMENTED DATA: Verify augmented images look reasonable

✓ START WITH FASTER R-CNN: Best accuracy with transfer learning

✓ USE GPU IF POSSIBLE: 10x faster training

✓ MONITOR TRAINING: Watch val_loss - it should decrease steadily


CONFIGURATION OPTIONS
═══════════════════════════════════════════════════════════════════════════════

Model Selection:
  - 'fasterrcnn': Best accuracy, slower (Recommended)
  - 'custom': Lighter, faster, good for simple cases

Augmentation Intensity:
  - Light: 5-10 augmentations per image (50+ base images)
  - Medium: 10-20 augmentations per image (20-50 base images)  
  - Heavy: 20-30 augmentations per image (5-20 base images) <- YOU ARE HERE

Training Duration:
  - Quick test: 10-20 epochs
  - Production: 50-100 epochs
  - With limited data: 100-150 epochs

Confidence Threshold:
  - Aggressive (more detections): 0.3-0.4
  - Balanced: 0.5-0.6
  - Conservative (fewer false positives): 0.7-0.8


TROUBLESHOOTING
═══════════════════════════════════════════════════════════════════════════════

Problem: "No worms detected"
→ Lower confidence threshold to 0.3
→ Check if training loss decreased
→ Verify augmented images have labels

Problem: "Too many false positives"
→ Increase confidence threshold to 0.7
→ Add more training epochs
→ Include negative samples (images without worms)

Problem: "Out of memory"
→ Reduce batch_size to 1 or 2
→ Use smaller images (resize to 512x512)
→ Use 'custom' model instead of 'fasterrcnn'

Problem: "Training very slow"
→ Use GPU if available
→ Reduce num_epochs for testing
→ Use 'custom' model (10x faster)

Problem: "Model not learning"
→ Check labels are correct format
→ Verify images and labels match (same filenames)
→ Try lower learning rate (0.0001)


EXPECTED RESULTS
═══════════════════════════════════════════════════════════════════════════════

With 10 annotated images + 20x augmentation (200 samples):
  ├─ Training time: 2-3 hours (GPU) / 8-12 hours (CPU)
  ├─ Expected accuracy: 75-85% mAP
  └─ Detection speed: 20-50ms per image

With 50 annotated images + 10x augmentation (500 samples):
  ├─ Training time: 4-6 hours (GPU) / 20-30 hours (CPU)
  ├─ Expected accuracy: 85-92% mAP
  └─ Detection speed: 20-50ms per image


NEXT STEPS
═══════════════════════════════════════════════════════════════════════════════

1. Read README.md for detailed documentation
2. Start with the annotation tool
3. Generate augmented data
4. Train a small model (10 epochs) to test
5. Scale up to full training
6. Deploy and test on real data
7. Iteratively improve with more annotations


GETTING HELP
═══════════════════════════════════════════════════════════════════════════════

Check these files:
  - README.md → Comprehensive documentation
  - complete_workflow.py → Working example
  - ml_model_training.py → Training code details
  - data_augmentation.py → Augmentation options


═══════════════════════════════════════════════════════════════════════════════
                        GOOD LUCK WITH YOUR RESEARCH!                        
═══════════════════════════════════════════════════════════════════════════════
